"""
Visualization module for career prediction system
Creates publication-ready figures for paper
Modified to separate PNG and PDF files into different folders
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json
from sklearn.metrics import confusion_matrix, roc_curve, auc
import warnings
from datetime import datetime
warnings.filterwarnings('ignore')

import sys
sys.path.append(str(Path(__file__).parent.parent))

# Set style for publication
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("husl")

# Set font sizes for paper
SMALL_SIZE = 10
MEDIUM_SIZE = 12
BIGGER_SIZE = 14

plt.rc('font', size=SMALL_SIZE)
plt.rc('axes', titlesize=BIGGER_SIZE)
plt.rc('axes', labelsize=MEDIUM_SIZE)
plt.rc('xtick', labelsize=SMALL_SIZE)
plt.rc('ytick', labelsize=SMALL_SIZE)
plt.rc('legend', fontsize=SMALL_SIZE)
plt.rc('figure', titlesize=BIGGER_SIZE)


class PaperVisualizer:
    """Create publication-ready visualizations with separated PNG and PDF folders"""
    
    def __init__(self, results_dir: str = 'results', save_dir: str = 'reports_figures'):
        # Get project root
        project_root = Path(__file__).parent.parent.parent
        
        self.results_dir = project_root / results_dir
        self.save_dir = project_root / save_dir
        
        # Create separate folders for images and PDFs
        self.image_dir = self.save_dir / 'images'
        self.pdf_dir = self.save_dir / 'pdfs'
        
        # Create directories if they don't exist
        for dir_path in [self.save_dir, self.image_dir, self.pdf_dir]:
            if not dir_path.exists():
                print(f"Creating directory: {dir_path}")
                dir_path.mkdir(parents=True, exist_ok=True)
        
        # Load all results
        self.load_results()
    
    def get_timestamped_filename(self, base_filename: str) -> str:
        """Add timestamp to filename to avoid overwriting"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        name_parts = base_filename.rsplit('.', 1)
        if len(name_parts) == 2:
            return f"{name_parts[0]}_{timestamp}.{name_parts[1]}"
        else:
            return f"{base_filename}_{timestamp}"
    
    def save_figure(self, base_filename: str, dpi: int = 300):
        """Save figure to both PNG and PDF folders"""
        png_filename = self.get_timestamped_filename(base_filename.replace('.pdf', '.png'))
        pdf_filename = self.get_timestamped_filename(base_filename.replace('.png', '.pdf'))
        
        plt.savefig(self.image_dir / png_filename, dpi=dpi, bbox_inches='tight')
        plt.savefig(self.pdf_dir / pdf_filename, bbox_inches='tight')
        
        print(f"  üì∑ PNG saved: images/{png_filename}")
        print(f"  üìÑ PDF saved: pdfs/{pdf_filename}")
        
    def load_results(self):
        """Load all experimental results"""
        self.results = {}
        
        # Load baseline results
        baseline_path = self.results_dir / 'baseline' / 'baseline_results_optimized.json'
        if baseline_path.exists():
            with open(baseline_path, 'r') as f:
                self.results['baseline'] = json.load(f)
        
        # Load advanced results
        for scenario in ['without_leaky', 'with_leaky']:
            val_path = self.results_dir / 'advanced' / scenario / 'validation_results.json'
            if val_path.exists():
                with open(val_path, 'r') as f:
                    if 'advanced' not in self.results:
                        self.results['advanced'] = {}
                    self.results['advanced'][scenario] = json.load(f)
    
    def create_model_comparison_plot(self):
        """Create main model comparison plot"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))
        
        # Prepare data
        models = []
        scenarios = []
        f1_scores = []
        model_types = []
        
        # Baseline models
        if 'baseline' in self.results:
            for scenario in ['without_leaky', 'with_leaky']:
                if scenario in self.results['baseline']:
                    for model in ['RandomForest', 'MLP']:
                        if model in self.results['baseline'][scenario]:
                            models.append(model)
                            scenarios.append('With Leaky' if scenario == 'with_leaky' else 'Without Leaky')
                            f1_scores.append(self.results['baseline'][scenario][model]['val_f1'])
                            model_types.append('Baseline')
        
        # Advanced models
        if 'advanced' in self.results:
            for scenario in ['without_leaky', 'with_leaky']:
                if scenario in self.results['advanced']:
                    for model in ['xgboost', 'catboost', 'ensemble']:
                        models.append(model.upper() if model != 'ensemble' else 'Ensemble')
                        scenarios.append('With Leaky' if scenario == 'with_leaky' else 'Without Leaky')
                        f1_scores.append(self.results['advanced'][scenario][model]['f1'])
                        model_types.append('Advanced')
        
        # Create DataFrame for easier plotting
        df_plot = pd.DataFrame({
            'Model': models,
            'Scenario': scenarios,
            'F1_Score': f1_scores,
            'Type': model_types
        })
        
        # Plot 1: F1 Scores by model and scenario
        scenario_colors = {'Without Leaky': '#FF6B6B', 'With Leaky': '#4ECDC4'}
        
        for scenario in df_plot['Scenario'].unique():
            scenario_data = df_plot[df_plot['Scenario'] == scenario]
            x_pos = range(len(scenario_data))
            if scenario == 'Without Leaky':
                x_pos = [x - 0.2 for x in x_pos]
            else:
                x_pos = [x + 0.2 for x in x_pos]
            
            bars = ax1.bar(x_pos, scenario_data['F1_Score'], 
                          width=0.4, label=scenario, 
                          color=scenario_colors[scenario], alpha=0.8)
            
            # Add value labels
            for bar in bars:
                height = bar.get_height()
                ax1.annotate(f'{height:.3f}',
                            xy=(bar.get_x() + bar.get_width() / 2, height),
                            xytext=(0, 3),
                            textcoords="offset points",
                            ha='center', va='bottom',
                            fontweight='bold', fontsize=9)
        
        ax1.set_xlabel('Models', fontweight='bold')
        ax1.set_ylabel('F1 Score', fontweight='bold')
        ax1.set_title('Model Performance Comparison', fontweight='bold', pad=20)
        ax1.set_xticks(range(len(df_plot[df_plot['Scenario'] == 'Without Leaky'])))
        ax1.set_xticklabels(df_plot[df_plot['Scenario'] == 'Without Leaky']['Model'], rotation=45)
        ax1.legend(frameon=True, fancybox=True, shadow=True)
        ax1.grid(axis='y', alpha=0.3)
        ax1.set_ylim(0, 1)
        
        # Plot 2: Impact of leaky column (percentage change)
        without_leaky = df_plot[df_plot['Scenario'] == 'Without Leaky'].set_index('Model')['F1_Score']
        with_leaky = df_plot[df_plot['Scenario'] == 'With Leaky'].set_index('Model')['F1_Score']
        
        # Calculate percentage change
        common_models = set(without_leaky.index) & set(with_leaky.index)
        pct_changes = [(with_leaky[model] - without_leaky[model]) / without_leaky[model] * 100 
                      for model in common_models]
        
        bars = ax2.bar(range(len(common_models)), pct_changes, 
                      color=['green' if x > 0 else 'red' for x in pct_changes], alpha=0.7)
        
        ax2.set_xticks(range(len(common_models)))
        ax2.set_xticklabels(list(common_models), rotation=45)
        ax2.set_xlabel('Model', fontweight='bold')
        ax2.set_ylabel('F1 Score Change (%)', fontweight='bold')
        ax2.set_title('Impact of Leaky Column', fontweight='bold', pad=20)
        ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.5)
        ax2.grid(axis='y', alpha=0.3)
        
        # Add value labels
        for bar in bars:
            height = bar.get_height()
            ax2.annotate(f'{height:+.1f}%',
                        xy=(bar.get_x() + bar.get_width() / 2, height),
                        xytext=(0, 3 if height > 0 else -15),
                        textcoords="offset points",
                        ha='center', va='bottom' if height > 0 else 'top',
                        fontweight='bold')
        
        plt.tight_layout()
        self.save_figure('model_comparison.png')
        plt.show()
    
    def get_latest_predictions_file(self, scenario: str = None):
        """Get the latest predictions file based on modification time"""
        pred_dir = Path('results/predictions')
        
        if not pred_dir.exists():
            print(f"Predictions directory not found: {pred_dir}")
            return None
        
        # Search pattern based on scenario
        if scenario:
            pattern = f'predictions_{scenario}_*.csv'
        else:
            pattern = 'predictions_*.csv'
        
        pred_files = list(pred_dir.glob(pattern))
        
        if not pred_files:
            # Fallback to any predictions file
            pred_files = list(pred_dir.glob('predictions_*.csv'))
            if not pred_files:
                print("No prediction files found")
                return None
        
        # Sort by modification time (newest first)
        latest_file = max(pred_files, key=lambda x: x.stat().st_mtime)
        
        print(f"Using latest predictions file: {latest_file.name}")
        return str(latest_file)
    
    def create_confusion_matrices(self, predictions_file: str = None, scenario: str = None):
        """Create confusion matrix visualization"""
        if predictions_file is None:
            predictions_file = self.get_latest_predictions_file(scenario)
            if not predictions_file:
                return
        
        df_pred = pd.read_csv(predictions_file)
        
        # Check if we have actual labels for confusion matrix
        if 'actual_target' not in df_pred.columns:
            print("No actual labels found for confusion matrix")
            return
        
        # Create confusion matrix
        y_true = df_pred['actual_target']
        y_pred = df_pred['prediction']
        
        cm = confusion_matrix(y_true, y_pred)
        
        fig, ax = plt.subplots(figsize=(8, 6))
        
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
                   xticklabels=['Tidak Sesuai', 'Sesuai'],
                   yticklabels=['Tidak Sesuai', 'Sesuai'])
        
        ax.set_xlabel('Predicted', fontweight='bold')
        ax.set_ylabel('Actual', fontweight='bold')
        ax.set_title('Confusion Matrix', fontweight='bold', pad=20)
        
        # Add accuracy text
        accuracy = (cm[0,0] + cm[1,1]) / cm.sum()
        ax.text(0.5, -0.1, f'Accuracy: {accuracy:.3f}', 
                ha='center', va='center', transform=ax.transAxes, 
                fontsize=12, fontweight='bold', 
                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
        
        plt.tight_layout()
        self.save_figure('confusion_matrix.png')
        plt.show()
    
    def create_feature_importance_plot(self):
        """Create feature importance visualization"""
        # Load SHAP importance if available
        shap_files = list(Path('results/advanced').glob('*/shap_feature_importance.csv'))
        
        if not shap_files:
            print("No SHAP feature importance files found")
            return
        
        fig, axes = plt.subplots(1, 2, figsize=(16, 6))
        
        for idx, (shap_file, scenario) in enumerate(zip(shap_files[:2], ['without_leaky', 'with_leaky'])):
            df_importance = pd.read_csv(shap_file)
            
            # Get top 15 features
            df_top = df_importance.nlargest(15, 'importance')
            
            # Plot
            ax = axes[idx]
            bars = ax.barh(range(len(df_top)), df_top['importance'])
            ax.set_yticks(range(len(df_top)))
            ax.set_yticklabels(df_top['feature'])
            ax.set_xlabel('SHAP Importance', fontweight='bold')
            ax.set_title(f'Feature Importance - {"With" if "with" in str(shap_file) else "Without"} Leaky Column',
                        fontweight='bold')
            ax.grid(axis='x', alpha=0.3)
            
            # Color gradient
            colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(bars)))
            for bar, color in zip(bars, colors):
                bar.set_color(color)
        
        plt.tight_layout()
        self.save_figure('feature_importance.png')
        plt.show()
    
    def create_prediction_distribution(self, predictions_file: str = None, scenario: str = None):
        """Create prediction distribution visualization"""
        if predictions_file is None:
            predictions_file = self.get_latest_predictions_file(scenario)
            if not predictions_file:
                return
        
        df_pred = pd.read_csv(predictions_file)
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))
        
        # Plot 1: Prediction distribution
        pred_counts = df_pred['prediction'].value_counts()
        colors = ['#FF6B6B', '#4ECDC4']
        
        wedges, texts, autotexts = ax1.pie(pred_counts.values, 
                                            labels=['Sesuai' if x == 'ya' else 'Tidak Sesuai' 
                                                   for x in pred_counts.index],
                                            autopct='%1.1f%%',
                                            colors=colors,
                                            startangle=90,
                                            textprops={'fontsize': 12, 'weight': 'bold'})
        
        ax1.set_title('Distribution of Predictions', fontweight='bold', pad=20)
        
        # Plot 2: Confidence distribution
        ax2.hist(df_pred['confidence'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        ax2.axvline(df_pred['confidence'].mean(), color='red', linestyle='--', 
                   linewidth=2, label=f'Mean: {df_pred["confidence"].mean():.3f}')
        ax2.set_xlabel('Confidence Score', fontweight='bold')
        ax2.set_ylabel('Frequency', fontweight='bold')
        ax2.set_title('Distribution of Prediction Confidence', fontweight='bold', pad=20)
        ax2.legend()
        ax2.grid(axis='y', alpha=0.3)
        
        plt.tight_layout()
        self.save_figure('prediction_distribution.png')
        plt.show()
    
    def create_temporal_analysis(self):
        """Create temporal degradation analysis"""
        fig, ax = plt.subplots(figsize=(10, 6))
        
        years = ['2016 (Validation)', '2017 (Test)']
        scenarios = ['Without Leaky', 'With Leaky']
        
        # Get actual values from results if available
        val_scores = {
            'Without Leaky': 0.7568,  # From your results
            'With Leaky': 0.8468
        }
        
        # Estimate test scores (you'll need actual values)
        test_scores = {
            'Without Leaky': 0.72,  # Example
            'With Leaky': 0.81      # Example
        }
        
        x = np.arange(len(years))
        width = 0.35
        
        for i, scenario in enumerate(scenarios):
            scores = [val_scores[scenario], test_scores[scenario]]
            bars = ax.bar(x + i*width - width/2, scores, width, 
                          label=scenario, alpha=0.8)
            
            # Add value labels
            for bar in bars:
                height = bar.get_height()
                ax.annotate(f'{height:.3f}',
                           xy=(bar.get_x() + bar.get_width() / 2, height),
                           xytext=(0, 3),
                           textcoords="offset points",
                           ha='center', va='bottom',
                           fontweight='bold')
        
        ax.set_xlabel('Dataset', fontweight='bold')
        ax.set_ylabel('F1 Score', fontweight='bold')
        ax.set_title('Temporal Performance Analysis', fontweight='bold', pad=20)
        ax.set_xticks(x)
        ax.set_xticklabels(years)
        ax.legend(frameon=True, fancybox=True, shadow=True)
        ax.grid(axis='y', alpha=0.3)
        ax.set_ylim(0, 1)
        
        plt.tight_layout()
        self.save_figure('temporal_analysis.png')
        plt.show()
    
    def create_all_visualizations(self, scenario: str = None):
        """Create all visualizations for the paper"""
        print("Creating visualizations for paper...")
        print(f"Using scenario: {scenario if scenario else 'latest available'}")
        print(f"üìÅ Images will be saved to: {self.image_dir}")
        print(f"üìÅ PDFs will be saved to: {self.pdf_dir}")
        
        print("\n1. Model Comparison Plot...")
        self.create_model_comparison_plot()
        
        print("\n2. Feature Importance Plot...")
        self.create_feature_importance_plot()
        
        print("\n3. Prediction Distribution...")
        self.create_prediction_distribution(scenario=scenario)
        
        print("\n4. Confusion Matrix...")
        self.create_confusion_matrices(scenario=scenario)
        
        print("\n5. Temporal Analysis...")
        self.create_temporal_analysis()
        
        print(f"\n‚úÖ All visualizations completed!")
        print(f"üì∑ PNG files: {self.image_dir}")
        print(f"üìÑ PDF files: {self.pdf_dir}")


def create_optuna_visualization():
    """Create Optuna optimization history plots"""
    import optuna
    import joblib
    
    # Get project root
    project_root = Path(__file__).parent.parent.parent
    save_dir = project_root / 'reports_figures'
    image_dir = save_dir / 'images'
    pdf_dir = save_dir / 'pdfs'
    
    # Create directories if they don't exist
    for dir_path in [image_dir, pdf_dir]:
        dir_path.mkdir(parents=True, exist_ok=True)
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    axes = axes.ravel()
    
    # Load Optuna studies with correct paths
    study_files = [
        (project_root / 'models/baseline/optuna_study_rf_no_leak.pkl', 'RF - Without Leaky'),
        (project_root / 'models/baseline/optuna_study_mlp_no_leak.pkl', 'MLP - Without Leaky'),
        (project_root / 'models/baseline/optuna_study_rf_with_leak.pkl', 'RF - With Leaky'),
        (project_root / 'models/baseline/optuna_study_mlp_with_leak.pkl', 'MLP - With Leaky')
    ]
    
    for idx, (file_path, title) in enumerate(study_files):
        if Path(file_path).exists():
            study = joblib.load(file_path)
            
            # Get trial values
            values = [trial.value for trial in study.trials if trial.value is not None]
            
            ax = axes[idx]
            ax.plot(range(len(values)), values, 'b-', alpha=0.6, linewidth=1)
            ax.scatter(range(len(values)), values, c='blue', s=20, alpha=0.6)
            
            # Mark best trial
            best_idx = np.argmax(values)
            ax.scatter(best_idx, values[best_idx], c='red', s=100, 
                      marker='*', label=f'Best: {values[best_idx]:.4f}')
            
            ax.set_xlabel('Trial', fontweight='bold')
            ax.set_ylabel('F1 Score', fontweight='bold')
            ax.set_title(title, fontweight='bold')
            ax.grid(True, alpha=0.3)
            ax.legend()
    
    plt.suptitle('Optuna Hyperparameter Optimization History', fontsize=16, fontweight='bold')
    plt.tight_layout()
    
    # Save to both folders
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    plt.savefig(image_dir / f'optuna_history_{timestamp}.png', dpi=300, bbox_inches='tight')
    plt.savefig(pdf_dir / f'optuna_history_{timestamp}.pdf', bbox_inches='tight')
    
    print(f"üì∑ PNG saved: images/optuna_history_{timestamp}.png")
    print(f"üìÑ PDF saved: pdfs/optuna_history_{timestamp}.pdf")
    
    plt.show()


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Create visualizations for career prediction system')
    parser.add_argument('--scenario', type=str, choices=['without_leaky', 'with_leaky'], 
                       default=None, help='Specific scenario to visualize (default: latest available)')
    
    args = parser.parse_args()
    
    # Create all visualizations
    visualizer = PaperVisualizer()
    visualizer.create_all_visualizations(scenario=args.scenario)
    
    # Also create Optuna plots if available
    try:
        create_optuna_visualization()
    except Exception as e:
        print(f"Could not create Optuna visualization: {e}")
    
    print("\nüéâ Visualization complete!")
    print("üìÅ Check 'reports_figures/images' for PNG files")
    print("üìÅ Check 'reports_figures/pdfs' for PDF files")